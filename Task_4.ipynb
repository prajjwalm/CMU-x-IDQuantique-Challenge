{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65065fb6",
   "metadata": {},
   "source": "# Task 4: Demonstrating Quantum Advantage"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this task we demonstrate how introducing a bias into a random number generator suddenly makes it possible for a ML based predictor to start predicting the next bits with reasonable accuracy.\n",
    "\n",
    "To do the same, we first attempt to -\n",
    "+ Run the predictor for random numbers generated from a Jitter RNG in a manner identical to what was done in Task 2.\n",
    "+ Run the same predictor after biasing all the bits to a small degree."
   ],
   "id": "ad9cbad2b104d0c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T07:46:00.756504Z",
     "start_time": "2025-05-18T07:46:00.754463Z"
    }
   },
   "cell_type": "code",
   "source": "from random import random",
   "id": "4ab73f7d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T07:46:00.847602Z",
     "start_time": "2025-05-18T07:46:00.772560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "from collections import deque\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "class JitterRNG:\n",
    "    def __init__(self, pool_size=256):\n",
    "        self.entropy_pool = deque(maxlen=pool_size)\n",
    "        self.pool_size = pool_size\n",
    "        self.last_time = None\n",
    "\n",
    "    def _collect_timing_jitter(self, iterations=1000):\n",
    "        \"\"\"\n",
    "        Collect entropy from timing variations between CPU operations\n",
    "        \"\"\"\n",
    "        jitter_data = []\n",
    "\n",
    "        self.last_time = time.perf_counter_ns()\n",
    "\n",
    "        for _ in range(iterations):\n",
    "            # We need to introduce variability somehow.\n",
    "            # In the following space, do some arbitrary computation to introduce variability.\n",
    "            # We're not going to judge this part. Just make it reasonable so your notebook\n",
    "            # doesn't take forever to run.\n",
    "\n",
    "            _ = math.sqrt(math.pow(math.pi, math.e) / math.pow(math.e, math.pi))\n",
    "\n",
    "            current_time = time.perf_counter_ns()\n",
    "\n",
    "            time_diff = current_time - self.last_time\n",
    "            # hint: the JitterRNG class has a last_time attribute,\n",
    "            # and you just computed the current time.\n",
    "\n",
    "            # Extract the least significant bits of the time difference\n",
    "            # This is where the true randomness comes from\n",
    "            lsb = time_diff & 0xFF # Get the lowest 8 bits of time_diff\n",
    "            # hint: bitwise ops\n",
    "            jitter_data.append(lsb)\n",
    "\n",
    "            self.last_time = current_time\n",
    "\n",
    "        return jitter_data\n",
    "\n",
    "    def fill_entropy_pool(self):\n",
    "        \"\"\"Fill the entropy pool with timing jitter data\"\"\"\n",
    "        # Collect enough jitter samples to fill the pool\n",
    "        jitter_data = self._collect_timing_jitter(self.pool_size)\n",
    "\n",
    "        # Add to the entropy pool\n",
    "        for value in jitter_data:\n",
    "            self.entropy_pool.append(value)\n",
    "\n",
    "        return jitter_data\n",
    "\n",
    "    def get_random_bytes(self, num_bytes=32):\n",
    "        \"\"\"Generate random bytes using the entropy pool\"\"\"\n",
    "        # Make sure we have enough entropy\n",
    "        if len(self.entropy_pool) < self.pool_size:\n",
    "            self.fill_entropy_pool()\n",
    "\n",
    "        # Mix the entropy pool using SHA-256\n",
    "        pool_bytes = bytes(self.entropy_pool)\n",
    "        mixed_entropy = hashlib.sha256(pool_bytes).digest()\n",
    "\n",
    "        # Create an output buffer\n",
    "        result = bytearray()\n",
    "\n",
    "        # Generate requested number of bytes\n",
    "        while len(result) < num_bytes:\n",
    "            # Add more entropy to the pool\n",
    "            self.fill_entropy_pool()\n",
    "\n",
    "            # Mix new entropy with previous hash\n",
    "            pool_bytes = bytes(self.entropy_pool)\n",
    "            h = hashlib.sha256()\n",
    "            h.update(mixed_entropy)\n",
    "            h.update(pool_bytes)\n",
    "            mixed_entropy = h.digest()\n",
    "\n",
    "            # Add to result\n",
    "            result.extend(mixed_entropy)\n",
    "\n",
    "        # Return only the requested number of bytes\n",
    "        return bytes(result[:num_bytes])\n",
    "\n",
    "    def get_random_int(self, min_val=0, max_val=100):\n",
    "        \"\"\"Generate a random integer between min_val and max_val (inclusive)\"\"\"\n",
    "        # Calculate how many bytes we need\n",
    "        range_size = max_val - min_val + 1\n",
    "        if range_size <= 0:\n",
    "            raise ValueError(\"Invalid range\")\n",
    "\n",
    "        # Calculate how many bits we need\n",
    "        bits_needed = range_size.bit_length()\n",
    "        bytes_needed = (bits_needed + 7) // 8\n",
    "\n",
    "        # Get random bytes\n",
    "        random_bytes = self.get_random_bytes(bytes_needed)\n",
    "\n",
    "        # Convert bytes to integer\n",
    "        value = int.from_bytes(random_bytes, byteorder='big')\n",
    "\n",
    "        # Map to our range\n",
    "        return min_val + (value % range_size)\n",
    "\n",
    "    def return_random_samples(self, sample_size=1000):\n",
    "        \"\"\"Analyze the randomness of the generator\"\"\"\n",
    "        # Generate samples\n",
    "        samples = []\n",
    "        for _ in range(sample_size):\n",
    "            samples.append(self.get_random_int(0, 255))\n",
    "\n",
    "        return samples\n",
    "\n",
    "\n",
    "jitter_rng = JitterRNG()\n",
    "random_data = jitter_rng.return_random_samples(1000)"
   ],
   "id": "6d4d184b0bf50f0e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T07:46:00.864283Z",
     "start_time": "2025-05-18T07:46:00.861376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bias_value(val: int, bias: float) -> int:\n",
    "    \"\"\"\n",
    "    Tweaks the first eight bits of the given number, making them 1 with ``bias`` probability,\n",
    "    \"\"\"\n",
    "    for i in range(8):\n",
    "        should_bias = random() < bias\n",
    "        if not should_bias:\n",
    "            continue\n",
    "        val = val | (1 << i)\n",
    "    return val\n",
    "\n",
    "\n",
    "def bias_data(random_data: list[int], bias: float) -> list[int]:\n",
    "    \"\"\"\n",
    "    Biases all the numbers in the given data and returns the biased list.\n",
    "    \"\"\"\n",
    "    return [bias_value(v, bias) for v in random_data]\n",
    "\n",
    "\n",
    "biased_data = bias_data(random_data, 0.3)"
   ],
   "id": "dd86e4b10ab43c1e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T07:47:10.291237Z",
     "start_time": "2025-05-18T07:46:00.874160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We try to predict the bits like in QRNGs and PRNGs.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NextNumberPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from: https://medium.com/@gpj/predict-next-number-using-pytorch-47187c1b8e33.\n",
    "    Modified to predict bits of random numbers instead of next numbers.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_width, layer_depth):\n",
    "        super(NextNumberPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, layer_width, layer_depth)\n",
    "        self.fc = nn.Linear(layer_width, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def train(model, data, num_epochs):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for _input_sequence, _target in data:\n",
    "            _input_sequence = torch.Tensor(_input_sequence).view(len(_input_sequence), -1)\n",
    "            _target = torch.Tensor(_target).view(len(_target), -1)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(_input_sequence)\n",
    "            loss = loss_fn(output, _target)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "for (sequence_type, sequence) in ((\"JitterRNG\", random_data), (\"BiasedJitterRNG\", biased_data)):\n",
    "    for i in range(5):\n",
    "        # These dimensions are adjustable, but this NN works well enough to prove our point.\n",
    "        model = NextNumberPredictor(40, 1)\n",
    "\n",
    "        data = [((num & (1 << i)) >> i) for num in sequence[:1000]]\n",
    "        N_TRAIN = 500\n",
    "        training_rngs = data[:N_TRAIN]\n",
    "        test_rngs     = data[N_TRAIN:]\n",
    "\n",
    "        data = [\n",
    "            (training_rngs[:100], training_rngs[1:101]),\n",
    "            (training_rngs[:200], training_rngs[1:201]),\n",
    "            (training_rngs[:300], training_rngs[1:301]),\n",
    "            (training_rngs[:400], training_rngs[1:401]),\n",
    "        ]\n",
    "\n",
    "        # Train the model\n",
    "        train(model, data, num_epochs=100)\n",
    "\n",
    "        # Use the model to make predictions\n",
    "        input_sequence = torch.Tensor(test_rngs[:100]).view(-1, 1)\n",
    "        output = model(input_sequence)\n",
    "        predicted_bits = ([0 if x < 0.5 else 1 for x in torch.flatten(output).tolist()])\n",
    "        actual_bits    = (test_rngs[1:101])\n",
    "\n",
    "        print(f\"Predicting bit#{i} of the {sequence_type} sequence: \"\n",
    "              f\"{sum(pred == actual for pred, actual in zip(predicted_bits, actual_bits))}% match.\")"
   ],
   "id": "e85a3f8ab8673fe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting bit#0 of the JitterRNG sequence: 45% match.\n",
      "Predicting bit#1 of the JitterRNG sequence: 50% match.\n",
      "Predicting bit#2 of the JitterRNG sequence: 58% match.\n",
      "Predicting bit#3 of the JitterRNG sequence: 45% match.\n",
      "Predicting bit#4 of the JitterRNG sequence: 52% match.\n",
      "Predicting bit#0 of the BaisedJitterRNG sequence: 65% match.\n",
      "Predicting bit#1 of the BaisedJitterRNG sequence: 61% match.\n",
      "Predicting bit#2 of the BaisedJitterRNG sequence: 62% match.\n",
      "Predicting bit#3 of the BaisedJitterRNG sequence: 60% match.\n",
      "Predicting bit#4 of the BaisedJitterRNG sequence: 65% match.\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
